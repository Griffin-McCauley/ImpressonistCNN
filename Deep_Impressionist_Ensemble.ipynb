{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV_qhAwO5Xa1",
        "outputId": "979f8fa7-bd59-4e8c-bf60-72841f90c108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6kEhyBVL5vYa"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btPyFN_M59BR"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download delayedkarma/impressionist-classifier-data\n",
        "! unzip impressionist-classifier-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Ue3xOiG6Axu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
        "from torch import Generator\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import itertools\n",
        "import time\n",
        "import copy\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torch.nn import Module\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch import manual_seed as torch_manual_seed\n",
        "from torch.cuda import max_memory_allocated, set_device, manual_seed_all\n",
        "from torch.backends import cudnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_seed(seed):\n",
        "    torch_manual_seed(seed)\n",
        "    manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "SEED = 6050\n",
        "setup_seed(SEED)"
      ],
      "metadata": {
        "id": "xafbuYN8t6Cy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3iWHFUOWlpDM"
      },
      "outputs": [],
      "source": [
        "artists = ['Cezanne', 'Degas', 'Gauguin', 'Hassam', 'Matisse', 'Monet', 'Pissarro', 'Renoir', 'Sargent', 'VanGogh']\n",
        "artists = os.listdir('training/training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdlFf5-v6_JN",
        "outputId": "dbc1ad31-0725-44b4-ffdb-585b750d01f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'training': 3988, 'validation': 495, 'testing': 495}\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "transformation = Compose([\n",
        "    Resize((256,256)),\n",
        "    ToTensor()\n",
        "])\n",
        "transformation_train = Compose([\n",
        "    torchvision.transforms.Resize((256,256)),\n",
        "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomRotation(20),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "image_datasets = {}\n",
        "image_datasets['training'] = ImageFolder(f'/content/training/training', transform=transformation_train)\n",
        "image_datasets['validation'] = ImageFolder(f'/content/validation/validation', transform=transformation)\n",
        "\n",
        "size_all_validation = len(image_datasets['validation'])\n",
        "size_test_from_validation = int(size_all_validation * 0.5)\n",
        "size_validation = size_all_validation - size_test_from_validation\n",
        "\n",
        "image_datasets['validation'], image_datasets['testing'] = random_split(image_datasets['validation'], [size_validation, size_test_from_validation], generator=Generator().manual_seed(SEED))\n",
        "\n",
        "BS = 32\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BS, shuffle=True) for x in ['training', 'validation', 'testing']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['training', 'validation', 'testing']}\n",
        "print(dataset_sizes)\n",
        "\n",
        "# set the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPBDnOr3FL57"
      },
      "source": [
        "## Model 1: ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bEwU1RFEuo6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c75c66-a29f-46f1-ab39-b1467173b73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight False\n",
            "bn1.weight False\n",
            "bn1.bias False\n",
            "layer1.0.conv1.weight False\n",
            "layer1.0.bn1.weight False\n",
            "layer1.0.bn1.bias False\n",
            "layer1.0.conv2.weight False\n",
            "layer1.0.bn2.weight False\n",
            "layer1.0.bn2.bias False\n",
            "layer1.0.conv3.weight False\n",
            "layer1.0.bn3.weight False\n",
            "layer1.0.bn3.bias False\n",
            "layer1.0.downsample.0.weight False\n",
            "layer1.0.downsample.1.weight False\n",
            "layer1.0.downsample.1.bias False\n",
            "layer1.1.conv1.weight False\n",
            "layer1.1.bn1.weight False\n",
            "layer1.1.bn1.bias False\n",
            "layer1.1.conv2.weight False\n",
            "layer1.1.bn2.weight False\n",
            "layer1.1.bn2.bias False\n",
            "layer1.1.conv3.weight False\n",
            "layer1.1.bn3.weight False\n",
            "layer1.1.bn3.bias False\n",
            "layer1.2.conv1.weight False\n",
            "layer1.2.bn1.weight False\n",
            "layer1.2.bn1.bias False\n",
            "layer1.2.conv2.weight False\n",
            "layer1.2.bn2.weight False\n",
            "layer1.2.bn2.bias False\n",
            "layer1.2.conv3.weight False\n",
            "layer1.2.bn3.weight False\n",
            "layer1.2.bn3.bias False\n",
            "layer2.0.conv1.weight False\n",
            "layer2.0.bn1.weight False\n",
            "layer2.0.bn1.bias False\n",
            "layer2.0.conv2.weight False\n",
            "layer2.0.bn2.weight False\n",
            "layer2.0.bn2.bias False\n",
            "layer2.0.conv3.weight False\n",
            "layer2.0.bn3.weight False\n",
            "layer2.0.bn3.bias False\n",
            "layer2.0.downsample.0.weight False\n",
            "layer2.0.downsample.1.weight False\n",
            "layer2.0.downsample.1.bias False\n",
            "layer2.1.conv1.weight False\n",
            "layer2.1.bn1.weight False\n",
            "layer2.1.bn1.bias False\n",
            "layer2.1.conv2.weight False\n",
            "layer2.1.bn2.weight False\n",
            "layer2.1.bn2.bias False\n",
            "layer2.1.conv3.weight False\n",
            "layer2.1.bn3.weight False\n",
            "layer2.1.bn3.bias False\n",
            "layer2.2.conv1.weight False\n",
            "layer2.2.bn1.weight False\n",
            "layer2.2.bn1.bias False\n",
            "layer2.2.conv2.weight False\n",
            "layer2.2.bn2.weight False\n",
            "layer2.2.bn2.bias False\n",
            "layer2.2.conv3.weight False\n",
            "layer2.2.bn3.weight False\n",
            "layer2.2.bn3.bias False\n",
            "layer2.3.conv1.weight False\n",
            "layer2.3.bn1.weight False\n",
            "layer2.3.bn1.bias False\n",
            "layer2.3.conv2.weight False\n",
            "layer2.3.bn2.weight False\n",
            "layer2.3.bn2.bias False\n",
            "layer2.3.conv3.weight False\n",
            "layer2.3.bn3.weight False\n",
            "layer2.3.bn3.bias False\n",
            "layer3.0.conv1.weight False\n",
            "layer3.0.bn1.weight False\n",
            "layer3.0.bn1.bias False\n",
            "layer3.0.conv2.weight False\n",
            "layer3.0.bn2.weight False\n",
            "layer3.0.bn2.bias False\n",
            "layer3.0.conv3.weight False\n",
            "layer3.0.bn3.weight False\n",
            "layer3.0.bn3.bias False\n",
            "layer3.0.downsample.0.weight False\n",
            "layer3.0.downsample.1.weight False\n",
            "layer3.0.downsample.1.bias False\n",
            "layer3.1.conv1.weight False\n",
            "layer3.1.bn1.weight False\n",
            "layer3.1.bn1.bias False\n",
            "layer3.1.conv2.weight False\n",
            "layer3.1.bn2.weight False\n",
            "layer3.1.bn2.bias False\n",
            "layer3.1.conv3.weight False\n",
            "layer3.1.bn3.weight False\n",
            "layer3.1.bn3.bias False\n",
            "layer3.2.conv1.weight False\n",
            "layer3.2.bn1.weight False\n",
            "layer3.2.bn1.bias False\n",
            "layer3.2.conv2.weight False\n",
            "layer3.2.bn2.weight False\n",
            "layer3.2.bn2.bias False\n",
            "layer3.2.conv3.weight False\n",
            "layer3.2.bn3.weight False\n",
            "layer3.2.bn3.bias False\n",
            "layer3.3.conv1.weight False\n",
            "layer3.3.bn1.weight False\n",
            "layer3.3.bn1.bias False\n",
            "layer3.3.conv2.weight False\n",
            "layer3.3.bn2.weight False\n",
            "layer3.3.bn2.bias False\n",
            "layer3.3.conv3.weight False\n",
            "layer3.3.bn3.weight False\n",
            "layer3.3.bn3.bias False\n",
            "layer3.4.conv1.weight False\n",
            "layer3.4.bn1.weight False\n",
            "layer3.4.bn1.bias False\n",
            "layer3.4.conv2.weight False\n",
            "layer3.4.bn2.weight False\n",
            "layer3.4.bn2.bias False\n",
            "layer3.4.conv3.weight False\n",
            "layer3.4.bn3.weight False\n",
            "layer3.4.bn3.bias False\n",
            "layer3.5.conv1.weight False\n",
            "layer3.5.bn1.weight False\n",
            "layer3.5.bn1.bias False\n",
            "layer3.5.conv2.weight False\n",
            "layer3.5.bn2.weight False\n",
            "layer3.5.bn2.bias False\n",
            "layer3.5.conv3.weight False\n",
            "layer3.5.bn3.weight False\n",
            "layer3.5.bn3.bias False\n",
            "layer4.0.conv1.weight False\n",
            "layer4.0.bn1.weight False\n",
            "layer4.0.bn1.bias False\n",
            "layer4.0.conv2.weight False\n",
            "layer4.0.bn2.weight False\n",
            "layer4.0.bn2.bias False\n",
            "layer4.0.conv3.weight False\n",
            "layer4.0.bn3.weight False\n",
            "layer4.0.bn3.bias False\n",
            "layer4.0.downsample.0.weight False\n",
            "layer4.0.downsample.1.weight False\n",
            "layer4.0.downsample.1.bias False\n",
            "layer4.1.conv1.weight False\n",
            "layer4.1.bn1.weight False\n",
            "layer4.1.bn1.bias False\n",
            "layer4.1.conv2.weight False\n",
            "layer4.1.bn2.weight False\n",
            "layer4.1.bn2.bias False\n",
            "layer4.1.conv3.weight False\n",
            "layer4.1.bn3.weight False\n",
            "layer4.1.bn3.bias False\n",
            "layer4.2.conv1.weight False\n",
            "layer4.2.bn1.weight False\n",
            "layer4.2.bn1.bias False\n",
            "layer4.2.conv2.weight False\n",
            "layer4.2.bn2.weight False\n",
            "layer4.2.bn2.bias False\n",
            "layer4.2.conv3.weight False\n",
            "layer4.2.bn3.weight False\n",
            "layer4.2.bn3.bias False\n",
            "fc.weight False\n",
            "fc.bias False\n"
          ]
        }
      ],
      "source": [
        "# define the model to have the pre-trained resnet 50 parameters\n",
        "model1 = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "# freeze all of the parameters in the model\n",
        "for param in model1.parameters():\n",
        "  param.requires_grad = False\n",
        "# unfreeze the parameters in the last residual block of the architecture\n",
        "for name, param in model1.named_parameters():\n",
        "  for i in [4]:\n",
        "    if name.startswith(f'layer{i}'):\n",
        "      param.requires_grad = True\n",
        "# EDIT DROPOUT RATE HERE (dropout actually doesn't help here, so let's use L2 regularization instead)\n",
        "DO = 0.0\n",
        "# construct the fully connected head which will receive the flattened convolutional output\n",
        "model1.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 512),\n",
        "               nn.BatchNorm1d(512),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Dropout(DO),\n",
        "               \n",
        "               nn.Linear(512, 128),\n",
        "               nn.BatchNorm1d(128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Dropout(DO),\n",
        "\n",
        "               nn.Linear(128, len(artists)))\n",
        "\n",
        "# Print the named parameters to confirm that the correct ones are frozen and unfrozen\n",
        "for name, param in model1.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "\n",
        "# load the model to device\n",
        "model1 = model1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'/content/drive/My Drive/resnetModel.pt'\n",
        "model1.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WheadXFlzUTn",
        "outputId": "c2a7396a-48e5-4e20-8717-76ab0a9b2505"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOMfRYZEFXhy"
      },
      "source": [
        "## Model 2: EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model training function\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    # initialize the start time\n",
        "    since = time.time()\n",
        "\n",
        "    # initialize the best weight configuration and accuracy of the model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # initialize the lists that will store the accuracies and losses across the epochs\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # iterate over the epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # each epoch has a training and validation phase\n",
        "        for phase in ['training', 'validation']:\n",
        "            if phase == 'training':\n",
        "                model.train()  # set model to training mode\n",
        "            else:\n",
        "                model.eval()   # set model to evaluate mode\n",
        "\n",
        "            # initialize the running losses and corrects\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # iterate over the data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward pass\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'training'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward pass\n",
        "                    # optimize only if in training phase\n",
        "                    if phase == 'training':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # calculate and update epoch statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # print epoch performance statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # store epoch performance statistics\n",
        "            if phase == 'training':\n",
        "              train_accs.append(epoch_acc.item())\n",
        "              train_losses.append(epoch_loss)\n",
        "            else:\n",
        "              val_accs.append(epoch_acc.item())\n",
        "              val_losses.append(epoch_loss)\n",
        "\n",
        "            # deep copy the model to reflect the best weight configuration\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    # print the training statistics\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_accs, train_losses, val_accs, val_losses"
      ],
      "metadata": {
        "id": "EvM8k5LA3q8I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sIYLbdexlPJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87042757-9c82-476c-958f-9a784fd3d1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.0.weight False\n",
            "features.0.1.weight False\n",
            "features.0.1.bias False\n",
            "features.1.0.block.0.0.weight False\n",
            "features.1.0.block.0.1.weight False\n",
            "features.1.0.block.0.1.bias False\n",
            "features.1.0.block.1.fc1.weight False\n",
            "features.1.0.block.1.fc1.bias False\n",
            "features.1.0.block.1.fc2.weight False\n",
            "features.1.0.block.1.fc2.bias False\n",
            "features.1.0.block.2.0.weight False\n",
            "features.1.0.block.2.1.weight False\n",
            "features.1.0.block.2.1.bias False\n",
            "features.2.0.block.0.0.weight False\n",
            "features.2.0.block.0.1.weight False\n",
            "features.2.0.block.0.1.bias False\n",
            "features.2.0.block.1.0.weight False\n",
            "features.2.0.block.1.1.weight False\n",
            "features.2.0.block.1.1.bias False\n",
            "features.2.0.block.2.fc1.weight False\n",
            "features.2.0.block.2.fc1.bias False\n",
            "features.2.0.block.2.fc2.weight False\n",
            "features.2.0.block.2.fc2.bias False\n",
            "features.2.0.block.3.0.weight False\n",
            "features.2.0.block.3.1.weight False\n",
            "features.2.0.block.3.1.bias False\n",
            "features.2.1.block.0.0.weight False\n",
            "features.2.1.block.0.1.weight False\n",
            "features.2.1.block.0.1.bias False\n",
            "features.2.1.block.1.0.weight False\n",
            "features.2.1.block.1.1.weight False\n",
            "features.2.1.block.1.1.bias False\n",
            "features.2.1.block.2.fc1.weight False\n",
            "features.2.1.block.2.fc1.bias False\n",
            "features.2.1.block.2.fc2.weight False\n",
            "features.2.1.block.2.fc2.bias False\n",
            "features.2.1.block.3.0.weight False\n",
            "features.2.1.block.3.1.weight False\n",
            "features.2.1.block.3.1.bias False\n",
            "features.3.0.block.0.0.weight False\n",
            "features.3.0.block.0.1.weight False\n",
            "features.3.0.block.0.1.bias False\n",
            "features.3.0.block.1.0.weight False\n",
            "features.3.0.block.1.1.weight False\n",
            "features.3.0.block.1.1.bias False\n",
            "features.3.0.block.2.fc1.weight False\n",
            "features.3.0.block.2.fc1.bias False\n",
            "features.3.0.block.2.fc2.weight False\n",
            "features.3.0.block.2.fc2.bias False\n",
            "features.3.0.block.3.0.weight False\n",
            "features.3.0.block.3.1.weight False\n",
            "features.3.0.block.3.1.bias False\n",
            "features.3.1.block.0.0.weight False\n",
            "features.3.1.block.0.1.weight False\n",
            "features.3.1.block.0.1.bias False\n",
            "features.3.1.block.1.0.weight False\n",
            "features.3.1.block.1.1.weight False\n",
            "features.3.1.block.1.1.bias False\n",
            "features.3.1.block.2.fc1.weight False\n",
            "features.3.1.block.2.fc1.bias False\n",
            "features.3.1.block.2.fc2.weight False\n",
            "features.3.1.block.2.fc2.bias False\n",
            "features.3.1.block.3.0.weight False\n",
            "features.3.1.block.3.1.weight False\n",
            "features.3.1.block.3.1.bias False\n",
            "features.4.0.block.0.0.weight False\n",
            "features.4.0.block.0.1.weight False\n",
            "features.4.0.block.0.1.bias False\n",
            "features.4.0.block.1.0.weight False\n",
            "features.4.0.block.1.1.weight False\n",
            "features.4.0.block.1.1.bias False\n",
            "features.4.0.block.2.fc1.weight False\n",
            "features.4.0.block.2.fc1.bias False\n",
            "features.4.0.block.2.fc2.weight False\n",
            "features.4.0.block.2.fc2.bias False\n",
            "features.4.0.block.3.0.weight False\n",
            "features.4.0.block.3.1.weight False\n",
            "features.4.0.block.3.1.bias False\n",
            "features.4.1.block.0.0.weight False\n",
            "features.4.1.block.0.1.weight False\n",
            "features.4.1.block.0.1.bias False\n",
            "features.4.1.block.1.0.weight False\n",
            "features.4.1.block.1.1.weight False\n",
            "features.4.1.block.1.1.bias False\n",
            "features.4.1.block.2.fc1.weight False\n",
            "features.4.1.block.2.fc1.bias False\n",
            "features.4.1.block.2.fc2.weight False\n",
            "features.4.1.block.2.fc2.bias False\n",
            "features.4.1.block.3.0.weight False\n",
            "features.4.1.block.3.1.weight False\n",
            "features.4.1.block.3.1.bias False\n",
            "features.4.2.block.0.0.weight False\n",
            "features.4.2.block.0.1.weight False\n",
            "features.4.2.block.0.1.bias False\n",
            "features.4.2.block.1.0.weight False\n",
            "features.4.2.block.1.1.weight False\n",
            "features.4.2.block.1.1.bias False\n",
            "features.4.2.block.2.fc1.weight False\n",
            "features.4.2.block.2.fc1.bias False\n",
            "features.4.2.block.2.fc2.weight False\n",
            "features.4.2.block.2.fc2.bias False\n",
            "features.4.2.block.3.0.weight False\n",
            "features.4.2.block.3.1.weight False\n",
            "features.4.2.block.3.1.bias False\n",
            "features.5.0.block.0.0.weight False\n",
            "features.5.0.block.0.1.weight False\n",
            "features.5.0.block.0.1.bias False\n",
            "features.5.0.block.1.0.weight False\n",
            "features.5.0.block.1.1.weight False\n",
            "features.5.0.block.1.1.bias False\n",
            "features.5.0.block.2.fc1.weight False\n",
            "features.5.0.block.2.fc1.bias False\n",
            "features.5.0.block.2.fc2.weight False\n",
            "features.5.0.block.2.fc2.bias False\n",
            "features.5.0.block.3.0.weight False\n",
            "features.5.0.block.3.1.weight False\n",
            "features.5.0.block.3.1.bias False\n",
            "features.5.1.block.0.0.weight False\n",
            "features.5.1.block.0.1.weight False\n",
            "features.5.1.block.0.1.bias False\n",
            "features.5.1.block.1.0.weight False\n",
            "features.5.1.block.1.1.weight False\n",
            "features.5.1.block.1.1.bias False\n",
            "features.5.1.block.2.fc1.weight False\n",
            "features.5.1.block.2.fc1.bias False\n",
            "features.5.1.block.2.fc2.weight False\n",
            "features.5.1.block.2.fc2.bias False\n",
            "features.5.1.block.3.0.weight False\n",
            "features.5.1.block.3.1.weight False\n",
            "features.5.1.block.3.1.bias False\n",
            "features.5.2.block.0.0.weight False\n",
            "features.5.2.block.0.1.weight False\n",
            "features.5.2.block.0.1.bias False\n",
            "features.5.2.block.1.0.weight False\n",
            "features.5.2.block.1.1.weight False\n",
            "features.5.2.block.1.1.bias False\n",
            "features.5.2.block.2.fc1.weight False\n",
            "features.5.2.block.2.fc1.bias False\n",
            "features.5.2.block.2.fc2.weight False\n",
            "features.5.2.block.2.fc2.bias False\n",
            "features.5.2.block.3.0.weight False\n",
            "features.5.2.block.3.1.weight False\n",
            "features.5.2.block.3.1.bias False\n",
            "features.6.0.block.0.0.weight False\n",
            "features.6.0.block.0.1.weight False\n",
            "features.6.0.block.0.1.bias False\n",
            "features.6.0.block.1.0.weight False\n",
            "features.6.0.block.1.1.weight False\n",
            "features.6.0.block.1.1.bias False\n",
            "features.6.0.block.2.fc1.weight False\n",
            "features.6.0.block.2.fc1.bias False\n",
            "features.6.0.block.2.fc2.weight False\n",
            "features.6.0.block.2.fc2.bias False\n",
            "features.6.0.block.3.0.weight False\n",
            "features.6.0.block.3.1.weight False\n",
            "features.6.0.block.3.1.bias False\n",
            "features.6.1.block.0.0.weight False\n",
            "features.6.1.block.0.1.weight False\n",
            "features.6.1.block.0.1.bias False\n",
            "features.6.1.block.1.0.weight False\n",
            "features.6.1.block.1.1.weight False\n",
            "features.6.1.block.1.1.bias False\n",
            "features.6.1.block.2.fc1.weight False\n",
            "features.6.1.block.2.fc1.bias False\n",
            "features.6.1.block.2.fc2.weight False\n",
            "features.6.1.block.2.fc2.bias False\n",
            "features.6.1.block.3.0.weight False\n",
            "features.6.1.block.3.1.weight False\n",
            "features.6.1.block.3.1.bias False\n",
            "features.6.2.block.0.0.weight False\n",
            "features.6.2.block.0.1.weight False\n",
            "features.6.2.block.0.1.bias False\n",
            "features.6.2.block.1.0.weight False\n",
            "features.6.2.block.1.1.weight False\n",
            "features.6.2.block.1.1.bias False\n",
            "features.6.2.block.2.fc1.weight False\n",
            "features.6.2.block.2.fc1.bias False\n",
            "features.6.2.block.2.fc2.weight False\n",
            "features.6.2.block.2.fc2.bias False\n",
            "features.6.2.block.3.0.weight False\n",
            "features.6.2.block.3.1.weight False\n",
            "features.6.2.block.3.1.bias False\n",
            "features.6.3.block.0.0.weight False\n",
            "features.6.3.block.0.1.weight False\n",
            "features.6.3.block.0.1.bias False\n",
            "features.6.3.block.1.0.weight False\n",
            "features.6.3.block.1.1.weight False\n",
            "features.6.3.block.1.1.bias False\n",
            "features.6.3.block.2.fc1.weight False\n",
            "features.6.3.block.2.fc1.bias False\n",
            "features.6.3.block.2.fc2.weight False\n",
            "features.6.3.block.2.fc2.bias False\n",
            "features.6.3.block.3.0.weight False\n",
            "features.6.3.block.3.1.weight False\n",
            "features.6.3.block.3.1.bias False\n",
            "features.7.0.block.0.0.weight True\n",
            "features.7.0.block.0.1.weight True\n",
            "features.7.0.block.0.1.bias True\n",
            "features.7.0.block.1.0.weight True\n",
            "features.7.0.block.1.1.weight True\n",
            "features.7.0.block.1.1.bias True\n",
            "features.7.0.block.2.fc1.weight True\n",
            "features.7.0.block.2.fc1.bias True\n",
            "features.7.0.block.2.fc2.weight True\n",
            "features.7.0.block.2.fc2.bias True\n",
            "features.7.0.block.3.0.weight True\n",
            "features.7.0.block.3.1.weight True\n",
            "features.7.0.block.3.1.bias True\n",
            "features.8.0.weight True\n",
            "features.8.1.weight True\n",
            "features.8.1.bias True\n",
            "classifier.1.weight False\n",
            "classifier.1.bias False\n",
            "classsifier.0.weight True\n",
            "classsifier.0.bias True\n",
            "classsifier.1.weight True\n",
            "classsifier.1.bias True\n",
            "classsifier.4.weight True\n",
            "classsifier.4.bias True\n",
            "classsifier.5.weight True\n",
            "classsifier.5.bias True\n",
            "classsifier.8.weight True\n",
            "classsifier.8.bias True\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "\n",
        "# Load the pre-trained EfficientNet-B0 model\n",
        "model2 = torchvision.models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "# Freeze all layers except the last two blocks\n",
        "for name, param in model2.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in model2.named_parameters():\n",
        "  for i in [7,8]:\n",
        "    if name.startswith(f'features.{i}'):\n",
        "      param.requires_grad = True\n",
        "\n",
        "# # Modify the fully connected head\n",
        "DO = 0.\n",
        "model2.classsifier = nn.Sequential(\n",
        "    nn.Linear(1280, 256),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(DO),\n",
        "\n",
        "    nn.Linear(256, 64),\n",
        "    nn.BatchNorm1d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(DO),\n",
        "\n",
        "    nn.Linear(64, len(artists))\n",
        ")\n",
        "\n",
        "# Print the named parameters to confirm that the correct ones are frozen and unfrozen\n",
        "for name, param in model2.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "\n",
        "# Load the model to device\n",
        "model2 = model2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# EDIT LEARNING RATE HERE (tune 0.01, 0.001, 0.0001 with batch size of 16)\n",
        "LR = 0.0005 # (fixed)\n",
        "\n",
        "# EDIT WEIGHT DECAY (L2 REGULARIZATION) HERE (tune 1e-5, 1e-4, 1e-3)\n",
        "WD = 1e-5\n",
        "\n",
        "# set the optimizer for the parameters of the whole model\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model2.parameters()), lr=LR, weight_decay=WD)"
      ],
      "metadata": {
        "id": "CVi_Hc905lE9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model for the desired number of epochs\n",
        "model2, train_accs, train_losses, val_accs, val_losses = train_model(model2, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "lsLwAKpo5tEl",
        "outputId": "4efeb0b1-af49-4bc9-e7e9-842bd2765a60"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "training Loss: 2.7184 Acc: 0.4975\n",
            "validation Loss: 1.1358 Acc: 0.6869\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "training Loss: 1.0193 Acc: 0.7292\n",
            "validation Loss: 0.8222 Acc: 0.7636\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "training Loss: 0.8020 Acc: 0.7711\n",
            "validation Loss: 0.7928 Acc: 0.7657\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "training Loss: 0.6588 Acc: 0.8062\n",
            "validation Loss: 0.7783 Acc: 0.7636\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b8112e727608>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model for the desired number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-cf3b41d4686b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# iterate over the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = f'/content/drive/My Drive/efficientnetModel.pt'\n",
        "# model2.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "zjup1O__zVGK",
        "outputId": "d03227d6-39d2-48ca-90b2-c510294ada1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f39a26685e4b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/content/drive/My Drive/efficientnetModel.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-_5bTorxLnq"
      },
      "source": [
        "## Model 3: GoogLeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px9baSEPQG8S",
        "outputId": "8e67a21f-bbdd-4d05-8b85-c3d5b91e120b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googlenet_pytorch\n",
            "  Downloading googlenet_pytorch-0.3.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from googlenet_pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->googlenet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->googlenet_pytorch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->googlenet_pytorch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->googlenet_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->googlenet_pytorch) (1.3.0)\n",
            "Installing collected packages: googlenet_pytorch\n",
            "Successfully installed googlenet_pytorch-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install googlenet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvf-gRBtP9y3",
        "outputId": "37ebbd85-1a91-4bda-ef05-ae6c7c2d2df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for googlenet\n",
            "conv1.conv.weight False\n",
            "conv1.bn.weight False\n",
            "conv1.bn.bias False\n",
            "conv2.conv.weight False\n",
            "conv2.bn.weight False\n",
            "conv2.bn.bias False\n",
            "conv3.conv.weight False\n",
            "conv3.bn.weight False\n",
            "conv3.bn.bias False\n",
            "inception3a.branch1.conv.weight False\n",
            "inception3a.branch1.bn.weight False\n",
            "inception3a.branch1.bn.bias False\n",
            "inception3a.branch2.0.conv.weight False\n",
            "inception3a.branch2.0.bn.weight False\n",
            "inception3a.branch2.0.bn.bias False\n",
            "inception3a.branch2.1.conv.weight False\n",
            "inception3a.branch2.1.bn.weight False\n",
            "inception3a.branch2.1.bn.bias False\n",
            "inception3a.branch3.0.conv.weight False\n",
            "inception3a.branch3.0.bn.weight False\n",
            "inception3a.branch3.0.bn.bias False\n",
            "inception3a.branch3.1.conv.weight False\n",
            "inception3a.branch3.1.bn.weight False\n",
            "inception3a.branch3.1.bn.bias False\n",
            "inception3a.branch4.1.conv.weight False\n",
            "inception3a.branch4.1.bn.weight False\n",
            "inception3a.branch4.1.bn.bias False\n",
            "inception3b.branch1.conv.weight False\n",
            "inception3b.branch1.bn.weight False\n",
            "inception3b.branch1.bn.bias False\n",
            "inception3b.branch2.0.conv.weight False\n",
            "inception3b.branch2.0.bn.weight False\n",
            "inception3b.branch2.0.bn.bias False\n",
            "inception3b.branch2.1.conv.weight False\n",
            "inception3b.branch2.1.bn.weight False\n",
            "inception3b.branch2.1.bn.bias False\n",
            "inception3b.branch3.0.conv.weight False\n",
            "inception3b.branch3.0.bn.weight False\n",
            "inception3b.branch3.0.bn.bias False\n",
            "inception3b.branch3.1.conv.weight False\n",
            "inception3b.branch3.1.bn.weight False\n",
            "inception3b.branch3.1.bn.bias False\n",
            "inception3b.branch4.1.conv.weight False\n",
            "inception3b.branch4.1.bn.weight False\n",
            "inception3b.branch4.1.bn.bias False\n",
            "inception4a.branch1.conv.weight False\n",
            "inception4a.branch1.bn.weight False\n",
            "inception4a.branch1.bn.bias False\n",
            "inception4a.branch2.0.conv.weight False\n",
            "inception4a.branch2.0.bn.weight False\n",
            "inception4a.branch2.0.bn.bias False\n",
            "inception4a.branch2.1.conv.weight False\n",
            "inception4a.branch2.1.bn.weight False\n",
            "inception4a.branch2.1.bn.bias False\n",
            "inception4a.branch3.0.conv.weight False\n",
            "inception4a.branch3.0.bn.weight False\n",
            "inception4a.branch3.0.bn.bias False\n",
            "inception4a.branch3.1.conv.weight False\n",
            "inception4a.branch3.1.bn.weight False\n",
            "inception4a.branch3.1.bn.bias False\n",
            "inception4a.branch4.1.conv.weight False\n",
            "inception4a.branch4.1.bn.weight False\n",
            "inception4a.branch4.1.bn.bias False\n",
            "inception4b.branch1.conv.weight False\n",
            "inception4b.branch1.bn.weight False\n",
            "inception4b.branch1.bn.bias False\n",
            "inception4b.branch2.0.conv.weight False\n",
            "inception4b.branch2.0.bn.weight False\n",
            "inception4b.branch2.0.bn.bias False\n",
            "inception4b.branch2.1.conv.weight False\n",
            "inception4b.branch2.1.bn.weight False\n",
            "inception4b.branch2.1.bn.bias False\n",
            "inception4b.branch3.0.conv.weight False\n",
            "inception4b.branch3.0.bn.weight False\n",
            "inception4b.branch3.0.bn.bias False\n",
            "inception4b.branch3.1.conv.weight False\n",
            "inception4b.branch3.1.bn.weight False\n",
            "inception4b.branch3.1.bn.bias False\n",
            "inception4b.branch4.1.conv.weight False\n",
            "inception4b.branch4.1.bn.weight False\n",
            "inception4b.branch4.1.bn.bias False\n",
            "inception4c.branch1.conv.weight False\n",
            "inception4c.branch1.bn.weight False\n",
            "inception4c.branch1.bn.bias False\n",
            "inception4c.branch2.0.conv.weight False\n",
            "inception4c.branch2.0.bn.weight False\n",
            "inception4c.branch2.0.bn.bias False\n",
            "inception4c.branch2.1.conv.weight False\n",
            "inception4c.branch2.1.bn.weight False\n",
            "inception4c.branch2.1.bn.bias False\n",
            "inception4c.branch3.0.conv.weight False\n",
            "inception4c.branch3.0.bn.weight False\n",
            "inception4c.branch3.0.bn.bias False\n",
            "inception4c.branch3.1.conv.weight False\n",
            "inception4c.branch3.1.bn.weight False\n",
            "inception4c.branch3.1.bn.bias False\n",
            "inception4c.branch4.1.conv.weight False\n",
            "inception4c.branch4.1.bn.weight False\n",
            "inception4c.branch4.1.bn.bias False\n",
            "inception4d.branch1.conv.weight False\n",
            "inception4d.branch1.bn.weight False\n",
            "inception4d.branch1.bn.bias False\n",
            "inception4d.branch2.0.conv.weight False\n",
            "inception4d.branch2.0.bn.weight False\n",
            "inception4d.branch2.0.bn.bias False\n",
            "inception4d.branch2.1.conv.weight False\n",
            "inception4d.branch2.1.bn.weight False\n",
            "inception4d.branch2.1.bn.bias False\n",
            "inception4d.branch3.0.conv.weight False\n",
            "inception4d.branch3.0.bn.weight False\n",
            "inception4d.branch3.0.bn.bias False\n",
            "inception4d.branch3.1.conv.weight False\n",
            "inception4d.branch3.1.bn.weight False\n",
            "inception4d.branch3.1.bn.bias False\n",
            "inception4d.branch4.1.conv.weight False\n",
            "inception4d.branch4.1.bn.weight False\n",
            "inception4d.branch4.1.bn.bias False\n",
            "inception4e.branch1.conv.weight False\n",
            "inception4e.branch1.bn.weight False\n",
            "inception4e.branch1.bn.bias False\n",
            "inception4e.branch2.0.conv.weight False\n",
            "inception4e.branch2.0.bn.weight False\n",
            "inception4e.branch2.0.bn.bias False\n",
            "inception4e.branch2.1.conv.weight False\n",
            "inception4e.branch2.1.bn.weight False\n",
            "inception4e.branch2.1.bn.bias False\n",
            "inception4e.branch3.0.conv.weight False\n",
            "inception4e.branch3.0.bn.weight False\n",
            "inception4e.branch3.0.bn.bias False\n",
            "inception4e.branch3.1.conv.weight False\n",
            "inception4e.branch3.1.bn.weight False\n",
            "inception4e.branch3.1.bn.bias False\n",
            "inception4e.branch4.1.conv.weight False\n",
            "inception4e.branch4.1.bn.weight False\n",
            "inception4e.branch4.1.bn.bias False\n",
            "inception5a.branch1.conv.weight True\n",
            "inception5a.branch1.bn.weight True\n",
            "inception5a.branch1.bn.bias True\n",
            "inception5a.branch2.0.conv.weight True\n",
            "inception5a.branch2.0.bn.weight True\n",
            "inception5a.branch2.0.bn.bias True\n",
            "inception5a.branch2.1.conv.weight True\n",
            "inception5a.branch2.1.bn.weight True\n",
            "inception5a.branch2.1.bn.bias True\n",
            "inception5a.branch3.0.conv.weight True\n",
            "inception5a.branch3.0.bn.weight True\n",
            "inception5a.branch3.0.bn.bias True\n",
            "inception5a.branch3.1.conv.weight True\n",
            "inception5a.branch3.1.bn.weight True\n",
            "inception5a.branch3.1.bn.bias True\n",
            "inception5a.branch4.1.conv.weight True\n",
            "inception5a.branch4.1.bn.weight True\n",
            "inception5a.branch4.1.bn.bias True\n",
            "inception5b.branch1.conv.weight True\n",
            "inception5b.branch1.bn.weight True\n",
            "inception5b.branch1.bn.bias True\n",
            "inception5b.branch2.0.conv.weight True\n",
            "inception5b.branch2.0.bn.weight True\n",
            "inception5b.branch2.0.bn.bias True\n",
            "inception5b.branch2.1.conv.weight True\n",
            "inception5b.branch2.1.bn.weight True\n",
            "inception5b.branch2.1.bn.bias True\n",
            "inception5b.branch3.0.conv.weight True\n",
            "inception5b.branch3.0.bn.weight True\n",
            "inception5b.branch3.0.bn.bias True\n",
            "inception5b.branch3.1.conv.weight True\n",
            "inception5b.branch3.1.bn.weight True\n",
            "inception5b.branch3.1.bn.bias True\n",
            "inception5b.branch4.1.conv.weight True\n",
            "inception5b.branch4.1.bn.weight True\n",
            "inception5b.branch4.1.bn.bias True\n",
            "aux1.conv.conv.weight True\n",
            "aux1.conv.bn.weight True\n",
            "aux1.conv.bn.bias True\n",
            "aux1.fc1.weight True\n",
            "aux1.fc1.bias True\n",
            "aux1.fc2.weight True\n",
            "aux1.fc2.bias True\n",
            "aux2.conv.conv.weight True\n",
            "aux2.conv.bn.weight True\n",
            "aux2.conv.bn.bias True\n",
            "aux2.fc1.weight True\n",
            "aux2.fc1.bias True\n",
            "aux2.fc2.weight True\n",
            "aux2.fc2.bias True\n",
            "fc.0.weight True\n",
            "fc.0.bias True\n",
            "fc.1.weight True\n",
            "fc.1.bias True\n",
            "fc.4.weight True\n",
            "fc.4.bias True\n",
            "fc.5.weight True\n",
            "fc.5.bias True\n",
            "fc.8.weight True\n",
            "fc.8.bias True\n"
          ]
        }
      ],
      "source": [
        "#pip install googlenet_pytorch\n",
        "# batch_size = 32, learning_rate = 0.0005, weight_decay = 1e-5, Data Augmentation\n",
        "\n",
        "from googlenet_pytorch import GoogLeNet\n",
        "model_google = GoogLeNet.from_pretrained(\"googlenet\")\n",
        "\n",
        "# freeze all of the parameters in the model\n",
        "for param in model_google.parameters():\n",
        "    param.requires_grad = False\n",
        "# unfreeze the parameters in the last residual block of the architecture\n",
        "for name, param in model_google.named_parameters():\n",
        "    for i in [5]:\n",
        "        if name.startswith(f'inception{5}') or name.startswith('aux'):\n",
        "            param.requires_grad = True\n",
        "\n",
        "# EDIT DROPOUT RATE HERE (dropout actually doesn't help here, so let's use L2 regularization instead)\n",
        "DO = 0.0\n",
        "# construct the fully connected head which will receive the flattened convolutional output\n",
        "\n",
        "'''\n",
        "The final layer of GoogLeNet is a global average pooling layer that reduces the spatial \n",
        "dimensions of the feature maps to 1x1 and produces a tensor of size (1, 1024).\n",
        "''' \n",
        "model_google.fc = nn.Sequential(\n",
        "               nn.Linear(1024, 256), # 2048 -> 1024\n",
        "               nn.BatchNorm1d(256),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Dropout(DO),\n",
        "               \n",
        "               nn.Linear(256, 64),\n",
        "               nn.BatchNorm1d(64),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Dropout(DO),\n",
        "\n",
        "               nn.Linear(64, len(artists)))\n",
        "\n",
        "# print all the named parameters in the model to confirm that the correct ones are frozen and unfrozen\n",
        "for name, param in model_google.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "\n",
        "model_google = model_google.to(device)\n",
        "model_google.aux_logits = False ### NEVER REMOVE THIS LINE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# EDIT LEARNING RATE HERE (tune 0.01, 0.001, 0.0001 with batch size of 16)\n",
        "LR = 0.0005 # (fixed)\n",
        "\n",
        "# EDIT WEIGHT DECAY (L2 REGULARIZATION) HERE (tune 1e-5, 1e-4, 1e-3)\n",
        "WD = 1e-5\n",
        "\n",
        "# set the optimizer for the parameters of the whole model\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_google.parameters()), lr=LR, weight_decay=WD)"
      ],
      "metadata": {
        "id": "vCUJ1bfa29Qj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model for the desired number of epochs\n",
        "model3, train_accs, train_losses, val_accs, val_losses = train_model(model_google, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "id": "9AqeYUVG3TMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path = f'/content/drive/My Drive/googlenetModel.pt'\n",
        "# model3.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "Hcpbg1jBzvQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO4N_tRzryc0"
      },
      "source": [
        "##**Final Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the test loop\n",
        "def ensemble_test_loop(dataloader, model1, model2, model3, loss_fn):\n",
        "  # calculate the size of the dataset and the number of batches\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  # initialize the model performance metrics\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  # set model to evaluate model\n",
        "  model1.eval()\n",
        "  model2.eval()\n",
        "\n",
        "  # iterate over the data and compute the performance metrics\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      pred1 = model1(X)\n",
        "      pred2 = model2(X)\n",
        "      pred = (pred1+pred2)/2\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  # print the performance metrics\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# evaluate the first model\n",
        "ensemble_test_loop(dataloaders['testing'], model1, model2, loss_fn)"
      ],
      "metadata": {
        "id": "zt2SmtYG4CnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b413ae-15ee-4541-88a0-ee713f7ca6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.552976 \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}